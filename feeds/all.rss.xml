<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Brad Lucas</title><link>/</link><description></description><atom:link href="/feeds/all.rss.xml" rel="self"></atom:link><lastBuildDate>Tue, 16 Dec 2014 00:00:00 +0800</lastBuildDate><item><title>摄像机相关知识及一些传感器</title><link>/blog/2014-12-CV_AR_Cpp_Code.html</link><description>&lt;p&gt;如有特别推荐的代码，请在本页留言，或者email我：cvchina AT gmail.com&lt;/p&gt;
&lt;div class="contents topic" id="id2"&gt;
&lt;p class="topic-title first"&gt;目录&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#general-library" id="id4"&gt;通用库/General Library&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#io-image-video-io" id="id5"&gt;图像，视频IO/Image, Video IO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ar-augmented-reality" id="id6"&gt;AR相关/Augmented Reality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#local-invariant-feature" id="id7"&gt;局部不变特征/Local Invariant Feature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#object-detection" id="id8"&gt;目标检测/Object Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ann" id="id9"&gt;（近似）最近邻/ANN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#slam-sfm" id="id10"&gt;SLAM &amp;amp; SFM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#segmentation" id="id11"&gt;图像分割/Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#tracking" id="id12"&gt;目标跟踪/Tracking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#line-detection" id="id13"&gt;直线检测/Line Detection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#finger-print" id="id14"&gt;指纹/Finger Print&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#image-retrieval" id="id15"&gt;图像检索/Image Retrieval&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#visual-salience" id="id16"&gt;视觉显著性/Visual Salience&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#fft-dwt" id="id17"&gt;FFT/DWT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#audio-processing" id="id18"&gt;音频处理/Audio processing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id19"&gt;版权声明&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="general-library"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;通用库/General Library&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;OpenCV: &lt;a class="reference external" href="http://opencv.willowgarage.com/"&gt;http://opencv.willowgarage.com/&lt;/a&gt;
无需多言。&lt;/p&gt;
&lt;p&gt;RAVL
Recognition And Vision Library. 线程安全。强大的IO机制。包含AAM。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.ee.surrey.ac.uk/CVSSP/Ravl/"&gt;http://www.ee.surrey.ac.uk/CVSSP/Ravl/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;CImg
很酷的一个图像处理包。整个库只有一个头文件。包含一个基于PDE的光流算法。&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://cimg.sourceforge.net/"&gt;http://cimg.sourceforge.net/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="io-image-video-io"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;图像，视频IO/Image, Video IO&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;FreeImage: &lt;a class="reference external" href="http://freeimage.sourceforge.net/"&gt;http://freeimage.sourceforge.net/&lt;/a&gt;
DevIL: &lt;a class="reference external" href="http://openil.sourceforge.net/"&gt;http://openil.sourceforge.net/&lt;/a&gt;
ImageMagick: &lt;a class="reference external" href="http://www.imagemagick.org/script/index.php"&gt;http://www.imagemagick.org/script/index.php&lt;/a&gt;
FFMPEG: &lt;a class="reference external" href="http://www.ffmpeg.org/"&gt;http://www.ffmpeg.org/&lt;/a&gt;
VideoInput: &lt;a class="reference external" href="http://www.muonics.net/school/spring05/videoInput/"&gt;http://www.muonics.net/school/spring05/videoInput/&lt;/a&gt;
portVideo: &lt;a class="reference external" href="http://portvideo.sourceforge.net/"&gt;http://portvideo.sourceforge.net/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ar-augmented-reality"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;AR相关/Augmented Reality&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;ARToolKit: &lt;a class="reference external" href="http://www.hitl.washington.edu/artoolkit/"&gt;http://www.hitl.washington.edu/artoolkit/&lt;/a&gt;
基于Marker的AR库&lt;/p&gt;
&lt;p&gt;ARToolKitPlus: &lt;a class="reference external" href="http://handheldar.icg.tugraz.at/artoolkit"&gt;http://handheldar.icg.tugraz.at/artoolkit&lt;/a&gt;
ARToolKit的增强版。实现了更好的姿态估计算法。&lt;/p&gt;
&lt;p&gt;PTAM: &lt;a class="reference external" href="http://www.robots.ox.ac.uk/~gk/PTAM/"&gt;http://www.robots.ox.ac.uk/~gk/PTAM/&lt;/a&gt;
实时的跟踪、SLAM、AR库。无需Marker，模板，内置传感器等。&lt;/p&gt;
&lt;p&gt;BazAR: &lt;a class="reference external" href="http://cvlab.epfl.ch/software/bazar/inde"&gt;http://cvlab.epfl.ch/software/bazar/inde&lt;/a&gt;
基于特征点检测和识别的AR库。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="local-invariant-feature"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;局部不变特征/Local Invariant Feature&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;VLFeat: &lt;a class="reference external" href="http://www.vlfeat.org/"&gt;http://www.vlfeat.org/&lt;/a&gt;
目前最好的Sift开源实现。同时包含了KD-tree，KD-Forest，BoW实现。&lt;/p&gt;
&lt;p&gt;Ferns: &lt;a class="reference external" href="http://cvlab.epfl.ch/software/ferns/index.php"&gt;http://cvlab.epfl.ch/software/ferns/index.php&lt;/a&gt;
基于Naive Bayesian Bundle的特征点识别。高速，但占用内存高。&lt;/p&gt;
&lt;p&gt;SIFT By Rob Hess: &lt;a class="reference external" href="http://blogs.oregonstate.edu/hess/cod"&gt;http://blogs.oregonstate.edu/hess/cod&lt;/a&gt;
基于OpenCV的Sift实现。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="object-detection"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;目标检测/Object Detection&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;AdaBoost By JianXin.Wu: &lt;a class="reference external" href="http://c2inet.sce.ntu.edu.sg/Jianxin/RareEvent/rare_event.htm"&gt;http://c2inet.sce.ntu.edu.sg/Jianxin/RareEvent/rare_event.htm&lt;/a&gt;
又一个AdaBoost实现。训练速度快。&lt;/p&gt;
&lt;p&gt;行人检测 By JianXin.Wu: &lt;a class="reference external" href="http://c2inet.sce.ntu.edu.sg/Jianxin/projects/Pedestrian/Pedestrian.html"&gt;http://c2inet.sce.ntu.edu.sg/Jianxin/projects/Pedestrian/Pedestrian.html&lt;/a&gt;
基于Centrist和Linear SVM的快速行人检测。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="ann"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;（近似）最近邻/ANN&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;FLANN: &lt;a class="reference external" href="http://www.cs.ubc.ca/~mariusm/index.p"&gt;http://www.cs.ubc.ca/~mariusm/index.p&lt;/a&gt;
目前最完整的（近似）最近邻开源库。不但实现了一系列查找算法，还包含了一种自动选取最快算法的机制。&lt;/p&gt;
&lt;p&gt;ANN: &lt;a class="reference external" href="http://www.cs.umd.edu/~mount/ANN/"&gt;http://www.cs.umd.edu/~mount/ANN/&lt;/a&gt;
另外一个近似最近邻库。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="slam-sfm"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id10"&gt;SLAM &amp;amp; SFM&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;SceneLib [LGPL]: &lt;a class="reference external" href="http://www.doc.ic.ac.uk/~ajd/Scene/"&gt;http://www.doc.ic.ac.uk/~ajd/Scene/&lt;/a&gt;
monoSLAM库。由Androw Davison开发。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="segmentation"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id11"&gt;图像分割/Segmentation&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;SLIC Super Pixel: &lt;a class="reference external" href="http://ivrg.epfl.ch/supplementary_material/RK_SLICSuperpixels/index.html"&gt;http://ivrg.epfl.ch/supplementary_material/RK_SLICSuperpixels/index.html&lt;/a&gt;
使用Simple Linear Iterative Clustering产生指定数目，近似均匀分布的Super Pixel。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="tracking"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id12"&gt;目标跟踪/Tracking&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;TLD: &lt;a class="reference external" href="http://info.ee.surrey.ac.uk/Personal/Z.Kalal/tld.html"&gt;http://info.ee.surrey.ac.uk/Personal/Z.Kalal/tld.html&lt;/a&gt;
基于Online Random Forest的目标跟踪算法。&lt;/p&gt;
&lt;p&gt;KLT: &lt;a class="reference external" href="http://www.ces.clemson.edu/~stb/klt/"&gt;http://www.ces.clemson.edu/~stb/klt/&lt;/a&gt;
Kanade-Lucas-Tracker&lt;/p&gt;
&lt;p&gt;Online boosting trackers: &lt;a class="reference external" href="http://www.vision.ee.ethz.ch/boostingTrackers/"&gt;http://www.vision.ee.ethz.ch/boostingTrackers/&lt;/a&gt;
Online Boosting Trackers&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="line-detection"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id13"&gt;直线检测/Line Detection&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;DSCC: &lt;a class="reference external" href="http://www.umiacs.umd.edu/~zhengyf/LineDetect.htm"&gt;http://www.umiacs.umd.edu/~zhengyf/LineDetect.htm&lt;/a&gt;
基于联通域连接的直线检测算法。&lt;/p&gt;
&lt;p&gt;LSD [GPL]: &lt;a class="reference external" href="http://www.ipol.im/pub/algo/gjmr_line_segment_detector/"&gt;http://www.ipol.im/pub/algo/gjmr_line_segment_detector/&lt;/a&gt;
基于梯度的，局部直线段检测算子。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="finger-print"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id14"&gt;指纹/Finger Print&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;pHash [GPL]: &lt;a class="reference external" href="http://phash.org/"&gt;http://phash.org/&lt;/a&gt;
基于感知的多媒体文件Hash算法。（提取，对比图像、视频、音频的指纹）&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="image-retrieval"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id15"&gt;图像检索/Image Retrieval&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;libpmk: &lt;a class="reference external" href="http://www.google.com/url"&gt;http://www.google.com/url&lt;/a&gt;?
Pyramid Matching Algorithm实现。&lt;/p&gt;
&lt;p&gt;vocsearch: &lt;a class="reference external" href="http://www.inf.ethz.ch/personal/fraundof/page2.html"&gt;http://www.inf.ethz.ch/personal/fraundof/page2.html&lt;/a&gt;
一个简单的的Vocabulary Tree实现。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="visual-salience"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id16"&gt;视觉显著性/Visual Salience&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Global Contrast Based Salient Region Detection: &lt;a class="reference external" href="http://cg.cs.tsinghua.edu.cn/people/~cmm/saliency/"&gt;http://cg.cs.tsinghua.edu.cn/people/~cmm/saliency/&lt;/a&gt;
Ming-Ming Cheng的视觉显著性算法。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fft-dwt"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id17"&gt;FFT/DWT&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;FFTW [GPL]: &lt;a class="reference external" href="http://www.fftw.org/"&gt;http://www.fftw.org/&lt;/a&gt;
最快，最好的开源FFT。&lt;/p&gt;
&lt;p&gt;FFTReal [WTFPL]: &lt;a class="reference external" href="http://ldesoras.free.fr/prod.html#src_fft"&gt;http://ldesoras.free.fr/prod.html#src_fft&lt;/a&gt;
轻量级的FFT实现。许可证是亮点。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="audio-processing"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id18"&gt;音频处理/Audio processing&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;STK [Free]: &lt;a class="reference external" href="https://ccrma.stanford.edu/software/stk"&gt;https://ccrma.stanford.edu/software/stk&lt;/a&gt;
音频处理，音频合成。&lt;/p&gt;
&lt;p&gt;libsndfile [LGPL]: &lt;a class="reference external" href="http://www.mega-nerd.com/libsndfile/"&gt;http://www.mega-nerd.com/libsndfile/&lt;/a&gt;
音频文件IO。&lt;/p&gt;
&lt;p&gt;libsamplerate [GPL ]: &lt;a class="reference external" href="http://www.mega-nerd.com/libsndfile/"&gt;http://www.mega-nerd.com/libsndfile/&lt;/a&gt;
音频重采样。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id19"&gt;版权声明&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;以上内容均来自：&lt;a class="reference external" href="http://www.cvchina.info/tag/ptam/"&gt;http://www.cvchina.info/tag/ptam/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brad Lucas</dc:creator><pubDate>Tue, 16 Dec 2014 00:00:00 +0800</pubDate><guid>tag:,2014-12-16:blog/2014-12-CV_AR_Cpp_Code.html</guid><category>CV</category><category>AR</category><category>Cpp</category><category>Code</category></item><item><title>摄像机相关知识及一些传感器</title><link>/blog/2014-12-Camera-Related-Knowledge-And-Some-Sensors.html</link><description>&lt;div class="contents topic" id="id2"&gt;
&lt;p class="topic-title first"&gt;目录&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ccd-cmos" id="id4"&gt;CCD &amp;amp; CMOS&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ccd" id="id5"&gt;CCD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#cmos" id="id6"&gt;CMOS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#cognachrome" id="id7"&gt;Cognachrome颜色跟踪系统&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#cmucam" id="id8"&gt;CMUcam机器人视觉传感器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#cmvision" id="id9"&gt;CMVision颜色跟踪软件库&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#psd" id="id10"&gt;PSD位置敏感探测器红外三角测距原理传感器模块&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id11"&gt;最后&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="ccd-cmos"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;CCD &amp;amp; CMOS&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;CCD和CMOS分别是两种常用的图像传感器，用来感知打在传感器上面光子的数量，输出对应到图像处理中就是我们常常看到的数字图像&lt;/strong&gt;&lt;/p&gt;
&lt;div class="section" id="ccd"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id5"&gt;CCD&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;CCD是于1969年由美国贝尔实验室的威拉德·博伊尔和乔治·史密斯所发明的。当时贝尔实验室正在发展图像电话和半导体气泡式存储器。将这两种新技术结起来后，博伊尔和史密斯得出一种设备，他们命名为“电荷‘气泡’组件”（Charge &amp;quot;Bubble&amp;quot; Devices）。&lt;/p&gt;
&lt;p&gt;这种设备的特性就是它能沿着一片半导体的表面传递电荷，便尝试用来做为记忆设备，当时只能从暂存器用“注入”电荷的方式输入记忆。但随即发现光电效应能使此种组件表面产生电荷，而组成数字图像。&lt;/p&gt;
&lt;p&gt;来自：(&lt;a class="reference external" href="http://zh.wikipedia.org/wiki"&gt;http://zh.wikipedia.org/wiki&lt;/a&gt;/感光耦合元件)、(&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Charge-coupled_device"&gt;http://en.wikipedia.org/wiki/Charge-coupled_device&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cmos"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id6"&gt;CMOS&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;互补式金属氧化物半导体（简称互补式金氧半；英语：Complementary Metal-Oxide-Semiconductor，缩写：CMOS）是一种集成电路制程，可在硅晶圆上制作出PMOS（p-type MOSFET）和NMOS（n-type MOSFET）元件，由于PMOS与NMOS在特性上为互补性，因此称为CMOS。
此制程可用来制作微处理器、 微控制器、静态随机存取内存以及互补式金属氧化物半导体图像传感器与其他数字逻辑电路。&lt;/p&gt;
&lt;p&gt;来自：(&lt;a class="reference external" href="http://zh.wikipedia.org/wiki"&gt;http://zh.wikipedia.org/wiki&lt;/a&gt;/互補式金屬氧化物半導體)、(&lt;a class="reference external" href="http://en.wikipedia.org/wiki/CMOS"&gt;http://en.wikipedia.org/wiki/CMOS&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="cognachrome"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;Cognachrome颜色跟踪系统&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;牛顿研究实验室(&lt;a class="reference external" href="http://www.newtonlabs.com/"&gt;http://www.newtonlabs.com/&lt;/a&gt;)的Cognachrome视觉系统(&lt;a class="reference external" href="http://www.newtonlabs.com/cognachrome/"&gt;http://www.newtonlabs.com/cognachrome/&lt;/a&gt;)是一个基于硬件的颜色跟踪传感器，能在专用处理器上以极快的速度跟踪颜色。&lt;/p&gt;
&lt;p&gt;系统根据用户定义的颜色，以60Hz速率检测色斑。Cognachrome系统最大可对每帧25个物体做检测和报告，对各物体独立地提供质心、界定的框体、面积、纵横比和主轴方向等信息。&lt;/p&gt;
&lt;p&gt;该传感器利用一个称作**不断设限**的技术来辨识各颜色。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cmucam"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;CMUcam机器人视觉传感器&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.cs.cmu.edu/~cmucam/Publications/cvpr-2001.pdf"&gt;http://www.cs.cmu.edu/~cmucam/Publications/cvpr-2001.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;由3个芯片组成：&lt;/p&gt;
&lt;blockquote&gt;
(1)CMOS成像芯片；
(2)SX28微处理器；
(3)Maxim RS232电平转换器；&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="cmvision"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;CMVision颜色跟踪软件库&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.cs.cmu.edu/~jbruce/cmvision/"&gt;http://www.cs.cmu.edu/~jbruce/cmvision/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;该传感器所用的基本算法，像Cognachrome一样，是不断设限的。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="psd"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id10"&gt;PSD位置敏感探测器红外三角测距原理传感器模块&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;位置灵敏探测器PSD (Position Sensitive Device)属于半导体器件。是一种对其感光面上入射光斑重心位置敏感的光电器件。即当入射光斑落在器件感光面的不同位置时，PSD将对应输出不同的电信号。通过对此输出电信号的处理，即可确定入射光斑在PSD的位置。入射光的强度和尺寸大小对PSD的位置输出信号均无关。PSD的位置输出只与入射光的“重心”位置有关。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;原理的简单说明&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;a class="reference external" href="http://wenda.chinabaike.com/b/9768/2013/1029/588781.html"&gt;http://wenda.chinabaike.com/b/9768/2013/1029/588781.html&lt;/a&gt;&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;一篇相关文章&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;a class="reference external" href="http://wr.lib.tsinghua.edu.cn/sites/default/files/1190692233038.pdf"&gt;http://wr.lib.tsinghua.edu.cn/sites/default/files/1190692233038.pdf&lt;/a&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id11"&gt;最后&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;以上内容均来自：《自主移动机器人导论》，感谢作者Roland Siegwart IIIah 以及 R. Nourbakhsh&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brad Lucas</dc:creator><pubDate>Tue, 16 Dec 2014 00:00:00 +0800</pubDate><guid>tag:,2014-12-16:blog/2014-12-Camera-Related-Knowledge-And-Some-Sensors.html</guid><category>Camera</category><category>CCD</category><category>CMOS</category><category>Low Cost</category></item><item><title>ExBot XI开发札记(二)iRobot Create底盘测试</title><link>/blog/2014-12-Exbot-XI-Development-2-iRobot-Create-Test.html</link><description>&lt;div class="contents topic" id="id1"&gt;
&lt;p class="topic-title first"&gt;目录&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id4"&gt;遥控控制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#node" id="id5"&gt;通过编写node代码控制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id6"&gt;最后&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;遥控控制&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;这部分请参考：Exbot xi开发札记（一）Exbot xi测试(&lt;a class="reference external" href="http://ljjyxz123.github.io/blog/2014-12-Exbot-XI-Development-1-Exbot-XI-Test.html"&gt;http://ljjyxz123.github.io/blog/2014-12-Exbot-XI-Development-1-Exbot-XI-Test.html&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="node"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;通过编写node代码控制&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;先上代码：
.. code-block:: cpp&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;#include &amp;lt;ros/ros.h&amp;gt;
#include &amp;lt;signal.h&amp;gt;
#include &amp;lt;geometry_msgs/Twist.h&amp;gt;&lt;/p&gt;
&lt;p&gt;ros::Publisher cmdVelPub;&lt;/p&gt;
&lt;p&gt;void shutdown(int sig)&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;{&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;cmdVelPub.publish(geometry_msgs::Twist());&lt;/p&gt;
&lt;p&gt;ROS_INFO(&amp;quot;exbot example move cpp ended!&amp;quot;);&lt;/p&gt;
&lt;p class="last"&gt;ros::shutdown();&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;int main(int argc, char “**”argv)&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;{&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;ros::init(argc, argv, &amp;quot;exbotxi_example_move&amp;quot;);
std::string topic = &amp;quot;cmd_vel&amp;quot;;
ros::NodeHandle node;
cmdVelPub = node.advertise&amp;lt;geometry_msgs::Twist&amp;gt;(topic, 1);
ros::Rate loopRate(50);
signal(SIGINT, shutdown);
ROS_INFO(&amp;quot;exbot_example_move cpp start...&amp;quot;);&lt;/p&gt;
&lt;p&gt;int rate = 50;
double linear_speed = 0.2;
double goal_distance = 1.0;
double linear_duration = goal_distance / linear_speed;&lt;/p&gt;
&lt;p&gt;double angular_speed = 1.0;
double goal_angle = 3.14/ 2.0;
double angular_duration = goal_angle / angular_speed;&lt;/p&gt;
&lt;p&gt;geometry_msgs::Twist speed;
//while(ros::ok())
for(int i=0; i&amp;lt;1; i++)&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;{&lt;/dt&gt;
&lt;dd&gt;&lt;p class="first"&gt;speed = geometry_msgs::Twist();&lt;/p&gt;
&lt;p&gt;int ticks = int(linear_duration * rate);
speed.linear.x = linear_speed;
//speed.angular.z = angular_speed;&lt;/p&gt;
&lt;p&gt;int t = 0;
for(t=0; t&amp;lt;ticks; t++)&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;{&lt;/dt&gt;
&lt;dd&gt;cmdVelPub.publish(speed);
loopRate.sleep();
//sleep(1);&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;}
//在旋转前停止机器人行走
speed = geometry_msgs::Twist();
cmdVelPub.publish(geometry_msgs::Twist());
sleep(1);
//loopRate.sleep();&lt;/p&gt;
&lt;p&gt;speed.angular.z = angular_speed;
ticks = int(goal_angle * rate);
for(t=0; t&amp;lt;ticks; t++)&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;{&lt;/dt&gt;
&lt;dd&gt;cmdVelPub.publish(speed);
loopRate.sleep();&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p class="last"&gt;cmdVelPub.publish(geometry_msgs::Twist());
loopRate.sleep();&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p class="last"&gt;return 0;&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;此代码实现了沿着直线走1.0m，顺时针旋转180度的功能。
我们下面来对代码进行解读：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#include &amp;lt;ros/ros.h&amp;gt;&lt;/span&gt;
&lt;span class="cp"&gt;#include &amp;lt;signal.h&amp;gt;&lt;/span&gt;
&lt;span class="cp"&gt;#include &amp;lt;geometry_msgs/Twist.h&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;一些头文件，geometry_msgs/Twist.h中包含了底盘的线速度和角速度信息。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ros&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;exbotxi_example_move&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;//初始化ROS&lt;/span&gt;
&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt; &lt;span class="n"&gt;topic&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;cmd_vel&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;//主题名字&lt;/span&gt;
&lt;span class="n"&gt;ros&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;NodeHandle&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;//定义节点&lt;/span&gt;
&lt;span class="n"&gt;cmdVelPub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;advertise&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;geometry_msgs&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Twist&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;topic&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;//发布geometry_msgs::Twist消息&lt;/span&gt;
&lt;span class="n"&gt;ros&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Rate&lt;/span&gt; &lt;span class="n"&gt;loopRate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;signal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SIGINT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shutdown&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;//用来接收Ctrl-C，退出程序的运行。&lt;/span&gt;
&lt;span class="n"&gt;ROS_INFO&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;exbot_example_move cpp start...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;linear_speed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;goal_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;linear_duration&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;goal_distance&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;linear_speed&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;angular_speed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;goal_angle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;3.14&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;angular_duration&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;goal_angle&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;angular_speed&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里定义了行走的线速度以及角速度。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;geometry_msgs&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Twist&lt;/span&gt; &lt;span class="n"&gt;speed&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;用来发布速度信息。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;speed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;geometry_msgs&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Twist&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

        &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;ticks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;linear_duration&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="n"&gt;speed&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;linear_speed&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="c1"&gt;//speed.angular.z = angular_speed;&lt;/span&gt;

        &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;ticks&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;cmdVelPub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;publish&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;speed&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="n"&gt;loopRate&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
                &lt;span class="c1"&gt;//sleep(1);&lt;/span&gt;

        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="c1"&gt;//在旋转前停止机器人行走&lt;/span&gt;
        &lt;span class="n"&gt;speed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;geometry_msgs&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Twist&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
        &lt;span class="n"&gt;cmdVelPub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;publish&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;geometry_msgs&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Twist&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
        &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="c1"&gt;//loopRate.sleep();&lt;/span&gt;

        &lt;span class="n"&gt;speed&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;angular&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;angular_speed&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;ticks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;goal_angle&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;ticks&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="p"&gt;{&lt;/span&gt;
                &lt;span class="n"&gt;cmdVelPub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;publish&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;speed&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="n"&gt;loopRate&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

        &lt;span class="p"&gt;}&lt;/span&gt;

        &lt;span class="n"&gt;cmdVelPub&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;publish&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;geometry_msgs&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;Twist&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
        &lt;span class="n"&gt;loopRate&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里，设置好线速度和角速度后，将speed发布出去，让iRobot Create可以接收到。
这里向前行走1.0m，旋转180.0度，执行一遍。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id6"&gt;最后&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;上面就是代码的简单解释，其实ROS的核心就是pub/sub机制，一个节点publish主题，另一个节点subscribe它。&lt;/p&gt;
&lt;p&gt;这样实现消息的传递。&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brad Lucas</dc:creator><pubDate>Tue, 16 Dec 2014 00:00:00 +0800</pubDate><guid>tag:,2014-12-16:blog/2014-12-Exbot-XI-Development-2-iRobot-Create-Test.html</guid><category>ExBot XI</category><category>iRobot Create</category><category>ASUS Xtion Pro Live</category><category>ROS</category></item><item><title>PTAM - Parallel Tracking and Mapping</title><link>/blog/2014-12-Ptam.html</link><description>&lt;div class="contents topic" id="id1"&gt;
&lt;p class="topic-title first"&gt;目录&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ptam" id="id3"&gt;PTAM简介&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id4"&gt;相关网站&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="ptam"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id3"&gt;PTAM简介&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;PTAM (Parallel Tracking and Mapping) is a camera tracking system for augmented reality. It requires no markers, pre-made maps, known templates, or inertial sensors. If you're unfamiliar with PTAM have a look at some videos made with PTAM.
&lt;a class="reference external" href="http://www.robots.ox.ac.uk/~gk/youtube.html"&gt;http://www.robots.ox.ac.uk/~gk/youtube.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;相关网站&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1.Parallel Tracking and Mapping for Small AR Workspaces - Source Code&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.robots.ox.ac.uk/~gk/PTAM/"&gt;http://www.robots.ox.ac.uk/~gk/PTAM/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.ROS下的PTAM包&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://wiki.ros.org/ptam"&gt;http://wiki.ros.org/ptam&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3.http://www.cvchina.info/tag/ptam/&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brad Lucas</dc:creator><pubDate>Tue, 16 Dec 2014 00:00:00 +0800</pubDate><guid>tag:,2014-12-16:blog/2014-12-Ptam.html</guid><category>PTAM</category><category>ROS</category><category>Tracking</category><category>Mapping</category></item><item><title>机器人云：RoboEarch</title><link>/blog/2014-12-RoboEarth.html</link><description>&lt;p&gt;它的目的和ROS一样，减少重复劳动，统一机器人标准。&lt;/p&gt;
&lt;div class="contents topic" id="id1"&gt;
&lt;p class="topic-title first"&gt;目录&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#roboearth" id="id3"&gt;RoboEarth官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#roboearthros" id="id4"&gt;RoboEarth与ROS的接口&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id5"&gt;最后&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="roboearth"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id3"&gt;RoboEarth官网&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://roboearth.org/"&gt;http://roboearth.org/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="roboearthros"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;RoboEarth与ROS的接口&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://wiki.ros.org/knowrob"&gt;http://wiki.ros.org/knowrob&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;最后&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;推荐几个朋友介绍的机器人相关网站：&lt;/p&gt;
&lt;p&gt;1.PodCast：可以下载机器人相关博客的音频文件。&lt;a class="reference external" href="http://www.robotspodcast.com/"&gt;http://www.robotspodcast.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2.日本的人形机器人: &lt;a class="reference external" href="http://global.kawada.jp/mechatronics/hrp3.html"&gt;http://global.kawada.jp/mechatronics/hrp3.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3.Talking Robots: &lt;a class="reference external" href="http://lis2.epfl.ch/resources/podcast/"&gt;http://lis2.epfl.ch/resources/podcast/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brad Lucas</dc:creator><pubDate>Tue, 16 Dec 2014 00:00:00 +0800</pubDate><guid>tag:,2014-12-16:blog/2014-12-RoboEarth.html</guid><category>RoboEarth</category><category>ROS</category><category>机器人云</category></item><item><title>人工智能的未来与人类的终极目标</title><link>/blog/2014-12-AI-And-Human-Final-Target.html</link><description>&lt;div class="contents topic" id="id2"&gt;
&lt;p class="topic-title first"&gt;目录&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id7"&gt;人工智能&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id4" id="id8"&gt;机器人伦理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id5" id="id9"&gt;人类的终极目标&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id6" id="id10"&gt;最后&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;人工智能&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;人工智能其实是一门很综合的学科，涉及到计算机科学，心理学，哲学，认知神经科学，数学，数理逻辑等多门学科。
目前人工智能处在起步阶段，但也是很关键的一个阶段。最近读《人工智能的未来》（《On Intelligence》）以及《GEB》，产生了很多感想。
人的思维和大脑到底是支持一元论还是二元论，即思维到底是由大脑生成的，还是由某种不可知的力量生成？
其实，不能轻易地选择其中任何一种答案，我们目前还没有能力去证明哪种说法是正确的或者错误的，唯一可行的做法是保持自己的观点，然后试图收集证据去证明它，或者当收集到的证据证明了它是错误的时候，就改变自己的观念，以转向正确的观点。&lt;/p&gt;
&lt;p&gt;我本人是支持一元论的观点，即思维是由大脑产生的，而不是某种不可知的力量。心理学上有这样一个实验，即用电击某个人的大脑的某个区域，人会产生一定的幻象或者感觉。比如，当刺激大脑的味觉区域时，人会感觉到甜味或者其他的味道。所以就有人提出人脑是分区域的，即我们可以精确地划分出指控我们的知觉，视觉，嗅觉，味觉等各个感觉的区域。
但认知神经科学的一些研究发现，人的大脑有大概的各个区域，但是这些区域并不是一成不变的，比如说，天生没有视觉的人，可能利用耳朵就能感觉到颜色或者实际的物体。大脑其实是一个可塑性极强的，而每一个区域都可以被训练成可以具有某种感知能力的区域。即大脑本身的构造和我们对这个世界的认识是一样的，即分层的认识观。
举个例子，我们知道，宇宙是由各个星球构成的，而地球是由各个国家构成的，每个国家是由各个城市构成的，每个城市是由各个区构成的，而每个区里都有各种各样的房子和建筑物，每个房子又是由各个家具构成的，每个家具是由或木质材料或铁质材料构成的，每种材料又是由分子构成的，分子是由原子构成的，原子是由质子、中子和电子构成的，而质子又是由夸克构成的，究竟还能不能往下继续分，这个谁也说不清，人的认知能力是受物理构成影响的，是有局限性的，所以物质的组成的细分程度是由人类自身决定的。
上面那个例子很形象地说明了大脑的层次构成（猜想），大脑也是分为各个层次的，粗层次和细层次。而人们识别都是由最高层的，也是最粗糙的层次开始，直到大脑可以识别这个物体为止，这是视觉的一般原理（猜想）。而进入我们大脑的其实是一串序列，而序列有公共相同的部分，如桌子和凳子都是由木材构成的，这样，表示物体就可以利用数据结构中树的表示，识别过程也可以变成一个搜索的过程。&lt;/p&gt;
&lt;p&gt;以上是对人脑的基本原理的一个很略的说明，而人自身能不能完全探知自己的奥秘？也许随着科学的进步，人们会对自己有越来越深的了解，但是总会有个极限，或是人类超越了这个极限，可以探知到所有人自身的奥秘。
人的逻辑世界本身是有局限性的，可能人类用来认识自己的逻辑世界本身就是不完备的，正如哥德尔定理所说的那样，人类最终会陷入一个个的悖论中，而唯一的方法就是讲人类所创建的这个逻辑大厦推倒，全部重来。
另外，这个世界以及人类本身是确定的还是随机的？一个比较可能的答案是随机的，而这个随机性是不是都能够由一些如均值和方差等统计规律来表示？答案可能是能，也可能是不能。
一旦涉及到宇宙这个大的空间中，或是人类自身更精细的角度中时，可能我们所熟知的物理和数学大厦就会失效。就像《生命是什么》中所说的那样，人类的模型可能是可以用量子力学来表示的，如人类的记忆及思维可能是一个能级跃迁的过程，而并不是连续的。&lt;/p&gt;
&lt;p&gt;我们再做一个假设，假设人类是可以完全被认知的，那么当人类自身已经没有秘密可言的时候，当宇宙中的全部奥秘都被探索到了以后，人类的目标又是什么？人们又会为什么而奋斗？
加入我们现在的目标是为了人类更好的生活而奋斗，为了探索这个世界而奋斗，那么目标实现之后呢？
这个问题似乎回到了哲学的基本问题，生命的本质，以及生命的意义。
这是个值得我们每一个人都仔细考虑的问题，也许考虑这个问题本身，也是我们的终极目标。&lt;/p&gt;
&lt;p&gt;这就引发了另一个问题，科学和人文的矛盾之处。
科学的进步很多时候是背离自然的，也会影响自然的不和谐，我们在以自己的想象来改造这个世界，至于这样的世界究竟对不对，会不会有负面影响，没有人会考虑，因为我们本身有自身的本性的缺点，无法克服。
既然不知道未来究竟如何，那么按照目前的节奏及方式走下去，看来是最合适的一种做法。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id8"&gt;机器人伦理&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;说到人工智能，很难不提到机器人，而机器人的伦理问题又是一个大的问题。
当机器人如电脑一般普及的时候，我们要考虑到会不会有Hacker利用机器人软件的漏洞来写病毒程序，而有些恐怖组织会不会利用机器人来杀人，那么当机器人杀人后，该不该负法律责任？如果机器人不该负，那么谁该来负这个责任？
想一想，其实这是一个很可怕的预言，就如科幻电影一般，在未来都会实现，而现在我们可以逃避这些问题，那时候的我们怎么办？
人生来就是要负责任的，真正能逃避的只有精神病患者和深居山林的人。
其实我不该把精神病患者归于这一类，精神病患者本身可能就是一个极端的天才，他们有更多的时间和空间去思考我们没时间思考的这些问题。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id9"&gt;人类的终极目标&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;人工智能终究是逃不过伦理的讨论及哲学的探讨的，而如果把所有关于人工智能的问题都列出来，可能就是一个新的哲学史，而太多并不意味着我们有理由不去思考。每个人对于人类终极目标的认识，对于哲学本质的许多问题的认识都是不同的，所以，每个人都有一个自己的问题清单，而不断地往自己的问题清单里添加新的问题，并且解决旧的问题，是一件很有意思的事情，即使这些事情没有答案。&lt;/p&gt;
&lt;p&gt;所以，思考吧，如果你能想到一丝的线索或者答案，都是人生的一种成长，而把人生思考明白了，我们的任务也就完成了，所以我把思考这些事情作为我的人生的终极目标。那么，你们呢？&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id10"&gt;最后&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;玄影游侠原创，
转载请注明出处。&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brad Lucas</dc:creator><pubDate>Mon, 15 Dec 2014 00:00:00 +0800</pubDate><guid>tag:,2014-12-15:blog/2014-12-AI-And-Human-Final-Target.html</guid><category>人工智能</category><category>AI</category><category>Strong AI</category></item><item><title>ExBot XI开发札记(一)ExBot XI测试</title><link>/blog/2014-12-Exbot-XI-Development-1-Exbot-XI-Test.html</link><description>&lt;p&gt;打算记录下来玩的过程，以及自己开发的一些实验demo。&lt;/p&gt;
&lt;div class="contents topic" id="id1"&gt;
&lt;p class="topic-title first"&gt;目录&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id2" id="id4"&gt;安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#exbot-xi" id="id5"&gt;ExBot XI的测试过程&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="reference internal" href="#ros" id="id6"&gt;10分钟上手玩ROS仿真机器人&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#id3" id="id7"&gt;最后&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id4"&gt;安装&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;从开封到完全装好只用了40分钟，还是因为我自己装错了好几次。&lt;/p&gt;
&lt;p&gt;里面配件非常全，甚至包括内六角扳手，减震垫等，想得很周到。&lt;/p&gt;
&lt;p&gt;iRobot Create的底盘也是原装的，包括原装的电池，充电过程比较快，2个小时左右吧，绿灯亮了就充满了。&lt;/p&gt;
&lt;p&gt;充满后可以用很长时间。&lt;/p&gt;
&lt;p&gt;摄像头用的ASUS Xtion Pro Live，摄像机和iRobot底盘都是通过U口与电脑相连。&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="exbot-xi"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id5"&gt;ExBot XI的测试过程&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;下面说一下Exbot xi的测试过程：&lt;/p&gt;
&lt;p&gt;硬件安装完毕后，&lt;/p&gt;
&lt;div class="section" id="ros"&gt;
&lt;h3&gt;&lt;a class="toc-backref" href="#id6"&gt;10分钟上手玩ROS仿真机器人&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;(1)测试iRobot Create 底盘&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主要命令如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;roscore ; 用来启动ros

roslaunch exbotxi_bringup minimal.launch ; 启动Create底盘

roslaunch turtlebot_teleop keyboard_teleop.launch ; 启动遥控turtlebot代码
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在弹出的命令窗口，应该就可以遥控Exbot xi了，通过'u', 'i', 'o', 'j', 'k', 'l', 'm', ',', '.'九个按键进行遥控。&lt;/p&gt;
&lt;p&gt;如果通过按键控制Create移动了，那么恭喜你，你的底盘已经可以成功跑起来了！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(2)测试ASUS Xtion Pro Live摄像头&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;roslaunch openni2_launch openni2.launch ; 启动ASUS摄像头

rosrun rqt_image_view rqt_image_view ; 启动rqt来观察图像
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在打开的rqt中，选择&amp;quot;/camera/rgb/image_raw&amp;quot;以及&amp;quot;/camera/depth/image_raw&amp;quot;主题可以分别观察ASUS采集到的彩色及深度图像。&lt;/p&gt;
&lt;p&gt;如果你看到了对应的彩色和深度图像，恭喜你，摄像头也测试成功了！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(3)好了，经过上述两步，底盘和摄像头都测试成功了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果你测试失败了，那么首先检查底盘和ASUS摄像头是否成功连接到电脑。&lt;/p&gt;
&lt;p&gt;首先，是否将底盘通过串转U口线，并且将U口连接到电脑上。&lt;/p&gt;
&lt;p&gt;再次，ASUS摄像头的USB线是否连接到电脑上。&lt;/p&gt;
&lt;p&gt;如果，硬件USB都已经连接，那么检查虚拟机下面的对应底盘和摄像头的图标是否连接？如果没有，则点击图标，选择&amp;quot;Connect&amp;quot;。&lt;/p&gt;
&lt;div class="note"&gt;
&lt;p class="first admonition-title"&gt;Note&lt;/p&gt;
&lt;p class="last"&gt;笔记本上的USB口不是每一个都能在虚拟机中识别底盘或者摄像头的，我的笔记本只有右上角的两个USB口可以成功连接到虚拟机。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;&lt;a class="toc-backref" href="#id7"&gt;最后&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;请关注我后面的Exbot XI经验分享。&lt;/p&gt;
&lt;/div&gt;
</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Brad Lucas</dc:creator><pubDate>Mon, 15 Dec 2014 00:00:00 +0800</pubDate><guid>tag:,2014-12-15:blog/2014-12-Exbot-XI-Development-1-Exbot-XI-Test.html</guid><category>ExBot XI</category><category>iRobot Create</category><category>ASUS Xtion Pro Live</category><category>ROS</category></item></channel></rss>